{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397bb0c9",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "383e015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df6033",
   "metadata": {},
   "source": [
    "## Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f43a425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easygoing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best-known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enticing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>puzzlement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quarrellously</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>underdog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>renaissance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>solid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>backwoods</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>renowned</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>proving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>emptiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incessantly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>harboring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stricken</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2-faces</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>infringe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>overreach</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mistake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  sentiment\n",
       "0       easygoing          1\n",
       "1           scare          0\n",
       "2      best-known          1\n",
       "3        enticing          1\n",
       "4      puzzlement          0\n",
       "5   quarrellously          0\n",
       "6        underdog          0\n",
       "7     renaissance          1\n",
       "8           solid          1\n",
       "9       backwoods          0\n",
       "10       renowned          1\n",
       "11        proving          1\n",
       "12      emptiness          0\n",
       "13    incessantly          0\n",
       "14      harboring          0\n",
       "15       stricken          0\n",
       "16        2-faces          0\n",
       "17       infringe          0\n",
       "18      overreach          0\n",
       "19        mistake          0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words = pd.DataFrame(\n",
    "    open(\"../data/negative-words.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"word\"]\n",
    ")\n",
    "\n",
    "pos_words = pd.DataFrame(\n",
    "    open(\"../data/positive-words.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"word\"]\n",
    ")\n",
    "\n",
    "neg_words[\"sentiment\"] = 0\n",
    "pos_words[\"sentiment\"] = 1\n",
    "\n",
    "neg_set = set(neg_words['word'])\n",
    "pos_set = set(pos_words['word'])\n",
    "\n",
    "\n",
    "#combine datasets\n",
    "word_df = pd.concat([pos_words, neg_words], ignore_index=True)\n",
    "\n",
    "#shuffle rows\n",
    "word_df = word_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "word_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81a8d",
   "metadata": {},
   "source": [
    "## Preparing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e23f87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled train set: \n",
      "                                       review  sentiment\n",
      "0  high quality, very fast, 2 sided printing          1\n",
      "1                Glare on LCD when outside.,          0\n",
      "2                            Cost, it's big!          0\n",
      "3                                 Everything          1\n",
      "4  features limited and not VCAST compatible          0\n",
      "\n",
      "\n",
      "Shuffled test set: \n",
      "                                               review  sentiment\n",
      "0  location of lens makes it easy to block when h...          0\n",
      "1             Great phone with superior battery life          1\n",
      "2              It goes through batteries to quickly.          0\n",
      "3                                    Very Good Price          1\n",
      "4                                        Single Band          0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_reviews = pd.DataFrame(\n",
    "    open(\"../data/negative-reviews.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "pos_reviews = pd.DataFrame(\n",
    "    open(\"../data/positive-reviews.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "neg_reviews[\"sentiment\"] = 0\n",
    "pos_reviews[\"sentiment\"] = 1\n",
    "\n",
    "# Split dataset into training and testing sets (80-20)\n",
    "neg_train, neg_test, pos_train, pos_test = train_test_split(neg_reviews, pos_reviews, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine and shuffle train set\n",
    "train =  pd.concat([neg_train, pos_train], ignore_index=True)\n",
    "train = train.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "# Combine and shuffle test set\n",
    "test = pd.concat([neg_test, pos_test],)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Shuffled train set: \\n\", train.head())\n",
    "print('\\n')\n",
    "print(\"Shuffled test set: \\n\", test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13fedb",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "659b2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\"i\", \"me\", \"my\", \"you\", \"your\"}\n",
    "\n",
    "def extract_features(review):\n",
    "    words = review.lower().split()\n",
    "    word_count = len(words)\n",
    "    has_exclaim = int(\"!\" in review)\n",
    "    pronoun_count = sum(1 for w in words if w in pronouns)\n",
    "    pos_count = sum(1 for w in words if w in pos_set)\n",
    "    neg_count = sum(1 for w in words if w in neg_set)\n",
    "    has_no = int(\"no\" in words)\n",
    "    log_length = math.log(word_count + 1)\n",
    "    question_count = review.count(\"?\")\n",
    "    sentiment_ratio = (pos_count - neg_count) / (word_count + 1)\n",
    "    intensifiers = {\"very\", \"extremely\", \"really\", \"absolutely\", \"totally\", \"completely\"}\n",
    "    intensifier_count = sum(1 for w in words if w in intensifiers)\n",
    "    negations = {\"not\", \"never\", \"neither\", \"nobody\", \"nothing\", \"nowhere\", \"no\"}\n",
    "    negation_count = sum(1 for w in words if w in negations)\n",
    "    caps_count = sum(1 for w in review.split() if w.isupper() and len(w) > 1)\n",
    "    avg_word_len = sum(len(w) for w in words) / (word_count + 1)\n",
    "    \n",
    "    return [\n",
    "        has_exclaim, \n",
    "        pronoun_count, \n",
    "        pos_count, \n",
    "        neg_count, \n",
    "        has_no,\n",
    "        log_length, \n",
    "        question_count, \n",
    "        sentiment_ratio, \n",
    "        intensifier_count,\n",
    "        negation_count, \n",
    "        caps_count, \n",
    "        avg_word_len\n",
    "    ]\n",
    "    \n",
    "# Apply to all reviews\n",
    "train_extra = np.array([extract_features(r) for r in train[\"review\"]])\n",
    "test_extra  = np.array([extract_features(r) for r in test[\"review\"]])\n",
    "\n",
    "# Standardize extra features\n",
    "scaler = StandardScaler()\n",
    "train_extra = scaler.fit_transform(train_extra)\n",
    "test_extra  = scaler.transform(test_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1649bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,      \n",
    "    ngram_range=(1,3),       \n",
    "    stop_words='english',\n",
    "    min_df=2,                \n",
    "    max_df=0.8,              \n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Fit TF-IDF on training reviews and transform\n",
    "X_train_tfidf = vectorizer.fit_transform(train[\"review\"])\n",
    "X_test_tfidf  = vectorizer.transform(test[\"review\"])\n",
    "\n",
    "# Labels\n",
    "y_train = train[\"sentiment\"].tolist()\n",
    "y_test  = test[\"sentiment\"].tolist()\n",
    "\n",
    "# hstack combines sparse TF-IDF with dense extra features\n",
    "X_train = hstack([X_train_tfidf, train_extra])\n",
    "X_test  = hstack([X_test_tfidf, test_extra])\n",
    "\n",
    "y_train = train[\"sentiment\"].tolist()\n",
    "y_test  = test[\"sentiment\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73cce85",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18f1c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.92875\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
