{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397bb0c9",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "383e015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df6033",
   "metadata": {},
   "source": [
    "## Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9f43a425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staunchness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>droop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shamelessness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stigmatize</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bleed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>affluence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>infiltrators</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>selfinterested</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>demonizing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>greasy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unsettling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lackadaisical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vibrating</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>groundless</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disagreeing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>struggling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relentlessly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>famed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>illuminati</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review  sentiment\n",
       "0          wonders          1\n",
       "1      staunchness          1\n",
       "2            droop          0\n",
       "3    shamelessness          0\n",
       "4       stigmatize          0\n",
       "5            bleed          0\n",
       "6        affluence          1\n",
       "7     infiltrators          0\n",
       "8   selfinterested          0\n",
       "9       demonizing          0\n",
       "10          greasy          0\n",
       "11      unsettling          0\n",
       "12   lackadaisical          0\n",
       "13       vibrating          0\n",
       "14      groundless          0\n",
       "15     disagreeing          0\n",
       "16      struggling          0\n",
       "17    relentlessly          0\n",
       "18           famed          1\n",
       "19      illuminati          1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words = pd.DataFrame(\n",
    "    open(\"../data/negative-words.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "pos_words = pd.DataFrame(\n",
    "    open(\"../data/positive-words.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "neg_words[\"sentiment\"] = 0\n",
    "pos_words[\"sentiment\"] = 1\n",
    "\n",
    "#combine datasets\n",
    "word_df = pd.concat([pos_words, neg_words], ignore_index=True)\n",
    "\n",
    "#shuffle rows\n",
    "word_df = word_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "word_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81a8d",
   "metadata": {},
   "source": [
    "## Preparing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e23f87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled train set: \n",
      "                                               review  sentiment\n",
      "0                     Ease of Use, Features, Quality          1\n",
      "1  8mb memory stick, slow shutter/focusing, weak ...          0\n",
      "2      Fast, Easy To Use, Reliable, Energy-efficient          1\n",
      "3  holster, speaker not loud enough, slow process...          0\n",
      "4          Small, Lite, simple to use and Very Sheik          1\n",
      "\n",
      "\n",
      "Shuffled test set: \n",
      "                                               review  sentiment\n",
      "0  poor battery life,no download ringtones, games...          0\n",
      "1                             Lightweight, reclining          1\n",
      "2                                        battery use          0\n",
      "3  Battery life, durability, good photo quality f...          1\n",
      "4      Wish it had an automatic retracting lens cap.          0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_reviews = pd.DataFrame(\n",
    "    open(\"../data/negative-reviews.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "pos_reviews = pd.DataFrame(\n",
    "    open(\"../data/positive-reviews.txt\", encoding=\"latin-1\").read().splitlines(),\n",
    "    columns=[\"review\"]\n",
    ")\n",
    "\n",
    "neg_reviews[\"sentiment\"] = 0\n",
    "pos_reviews[\"sentiment\"] = 1\n",
    "\n",
    "# Split dataset into training and testing sets (90-10)\n",
    "neg_train, neg_test, pos_train, pos_test = train_test_split(neg_reviews, pos_reviews, test_size=0.1, random_state=42)\n",
    "\n",
    "# Combine and shuffle train set\n",
    "train =  pd.concat([neg_train, pos_train], ignore_index=True)\n",
    "train = train.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "# Combine and shuffle test set\n",
    "test = pd.concat([neg_test, pos_test],)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Shuffled train set: \\n\", train.head())\n",
    "print('\\n')\n",
    "print(\"Shuffled test set: \\n\", test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13fedb",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "659b2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\"i\", \"me\", \"my\", \"you\", \"your\"}\n",
    "\n",
    "def extract_features(review):\n",
    "    words = review.lower().split()\n",
    "    word_count = len(words)\n",
    "    return[\n",
    "        int(\"!\" in review),\n",
    "        sum(1 for w in words if w in pronouns),\n",
    "        int(\"no\" in words),\n",
    "        math.log(word_count + 1),\n",
    "        word_count,\n",
    "        review.count(\"?\")\n",
    "    ]\n",
    "    \n",
    "# Apply to all reviews\n",
    "train_extra = np.array([extract_features(r) for r in train[\"review\"]])\n",
    "test_extra  = np.array([extract_features(r) for r in test[\"review\"]])\n",
    "\n",
    "# Standardize extra features\n",
    "scaler = StandardScaler()\n",
    "train_extra = scaler.fit_transform(train_extra)\n",
    "test_extra  = scaler.transform(test_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1649bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,    \n",
    "    ngram_range=(1,3),   \n",
    "    stop_words='english'  \n",
    ")\n",
    "\n",
    "# Fit TF-IDF on training reviews and transform\n",
    "X_train_tfidf = vectorizer.fit_transform(train[\"review\"])\n",
    "X_test_tfidf  = vectorizer.transform(test[\"review\"])\n",
    "\n",
    "# Labels\n",
    "y_train = train[\"sentiment\"].tolist()\n",
    "y_test  = test[\"sentiment\"].tolist()\n",
    "\n",
    "# hstack combines sparse TF-IDF with dense extra features\n",
    "X_train = hstack([X_train_tfidf, train_extra])\n",
    "X_test  = hstack([X_test_tfidf, test_extra])\n",
    "\n",
    "y_train = train[\"sentiment\"].tolist()\n",
    "y_test  = test[\"sentiment\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73cce85",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18f1c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.921\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
